{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1P7xl2LFnxZm_nDPuMmV0taDuaI4B6_Hi",
      "authorship_tag": "ABX9TyM3Om9XrwxXVnT/IiLDRJnj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sudenaz11/hu-bby162-2024/blob/main/weborumce%C4%9Fi_ipynb_adl%C4%B1_not_defterinin_kopyas%C4%B1_ipynb_adl%C4%B1_not_defterinin_kopyas%C4%B1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "from google.colab import files\n",
        "webUrl = widgets.Text(value=\"\", description=\"Web URL:\")\n",
        "slider = widgets.IntSlider(min=1, max=5, step=1, value=2, description=\"Derinlik Seviyesi\")\n",
        "button = widgets.Button(description=\"Taramayı Başlat!\")\n",
        "cizgi = widgets.HTML(value=\"<hr>\")\n",
        "output_file = \"tarama_sonuclari.txt\"\n",
        "visited_pages = []\n",
        "display(webUrl)\n",
        "display(slider)\n",
        "display(button)\n",
        "display(cizgi)\n",
        "def crawl(url, depth, max_depth):\n",
        "    if depth > max_depth:\n",
        "        return\n",
        "    if url in visited_pages:\n",
        "        return\n",
        "    visited_pages.append(url)\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        title = soup.title.string if soup.title else 'Başlık Yok'\n",
        "        with open(output_file, 'a') as f:\n",
        "            f.write(f\"[Seviye {depth}] URL: {url}, Başlık: {title}\\n\")\n",
        "        print(f\"[Seviye {depth}] {url} - {title}\")\n",
        "        links = soup.find_all('a', href=True)\n",
        "        new_links = [link['href'] for link in links if link['href'].startswith('http')]\n",
        "        for link in new_links:\n",
        "            crawl(link, depth + 1, max_depth)\n",
        "            time.sleep(1)\n",
        "    except Exception as e:\n",
        "        print(f\"Hata oluştu: {e}\")\n",
        "def on_button_clicked(b):\n",
        "    url = webUrl.value\n",
        "    max_depth = slider.value\n",
        "    with open(output_file, 'w') as f:\n",
        "        f.write(\"Web Tarama Sonuçları\\n\")\n",
        "        f.write(\"====================\\n\\n\")\n",
        "\n",
        "    print(f\"Tarama başlatıldı! Başlangıç URL: {url}, Derinlik Seviyesi: {max_depth}\")\n",
        "    crawl(url, 1, max_depth)\n",
        "\n",
        "    print(f\"Tarama tamamlandı! Sonuçlar {output_file} dosyasına kaydedildi.\")\n",
        "button.on_click(on_button_clicked)\n",
        "def download_results():\n",
        "    files.download(output_file)\n",
        "download_button = widgets.Button(description=\"Sonuçları İndir\")\n",
        "display(download_button)\n",
        "download_button.on_click(lambda x: download_results())"
      ],
      "metadata": {
        "id": "4Y1cAGatH5Hq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}